{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3816511a-f93c-45b2-a7b6-2098a4bff742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5575dd-fb9c-4c55-9d23-8be979952523",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./kaggle/input/tweet-sentiment-extraction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f94ea5-165d-408e-9fb6-ae9e234032f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2339a9b08b</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16fab9f95b</td>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>like</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74a76f6e0a</td>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>DANGERously</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04dd1d2e34</td>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bbe3cbf620</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text   \n",
       "0   cb774db0d1                I`d have responded, if I were going  \\\n",
       "1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7   50e14c0bb8                                         Soooo high   \n",
       "8   e050245fbd                                        Both of you   \n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
       "11  16fab9f95b  I really really like the song Love Story by Ta...   \n",
       "12  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
       "13  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n",
       "14  bbe3cbf620                         test test from the LG enV2   \n",
       "\n",
       "                                        selected_text sentiment  \n",
       "0                 I`d have responded, if I were going   neutral  \n",
       "1                                            Sooo SAD  negative  \n",
       "2                                         bullying me  negative  \n",
       "3                                      leave me alone  negative  \n",
       "4                                       Sons of ****,  negative  \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                 fun  positive  \n",
       "7                                          Soooo high   neutral  \n",
       "8                                         Both of you   neutral  \n",
       "9                        Wow... u just became cooler.  positive  \n",
       "10  as much as i love to be hopeful, i reckon the ...   neutral  \n",
       "11                                               like  positive  \n",
       "12                                        DANGERously  negative  \n",
       "13                                               lost  negative  \n",
       "14                         test test from the LG enV2   neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1573a7-e1a8-45c5-8b61-d8adc99a536c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4d3749-fa87-4e07-97a3-fece965e6721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758de209-04e1-440f-8a73-24cdc9438aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>7781</td>\n",
       "      <td>5861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11118</td>\n",
       "      <td>11117</td>\n",
       "      <td>11111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>8582</td>\n",
       "      <td>5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID   text  selected_text\n",
       "sentiment                              \n",
       "negative     7781   7781           5861\n",
       "neutral     11118  11117          11111\n",
       "positive     8582   8582           5537"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('sentiment').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a20094-b9ce-4c9d-9b2a-e0d910d5a5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         selected_text sentiment\n",
       "0  I`d have responded, if I were going   neutral\n",
       "1                             Sooo SAD  negative\n",
       "2                          bullying me  negative\n",
       "3                       leave me alone  negative\n",
       "4                        Sons of ****,  negative"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['selected_text','sentiment']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f94a5d-a800-4e87-b8b5-74ca696396b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"selected_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bf1c82-f629-4893-ad4f-e367568a25f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"selected_text\"].fillna(\"No content\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c82b42-9128-4f46-b08d-59325ac50385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    # Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3ec572-02ef-448a-99f5-78a1bad1d1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I`d have responded, if I were going',\n",
       " 'Sooo SAD',\n",
       " 'bullying me',\n",
       " 'leave me alone',\n",
       " 'Sons of ****,']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "# Splitting pd.Series to list\n",
    "data_to_list = train['selected_text'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b4bb46-c53e-43a9-b366-e42ec00ca2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['have', 'responded', 'if', 'were', 'going'], ['sooo', 'sad'], ['bullying', 'me'], ['leave', 'me', 'alone'], ['sons', 'of'], ['some', 'shameless', 'plugging', 'for', 'the', 'best', 'rangers', 'forum', 'on', 'earth'], ['fun'], ['soooo', 'high'], ['both', 'of', 'you'], ['wow', 'just', 'became', 'cooler']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03203d77-9a85-4efe-a23b-d65599906810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "316844cb-3fd2-4d03-84a9-c62ddd021744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2698977a-d929-47dc-8376-1241266ce093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have responded if were going', 'sooo sad', 'bullying me', 'leave me alone', 'sons of']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc8f0f3-8fd1-4318-a08a-de655f17ed90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae82866-99f8-4155-b39f-933f5c73899b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.array(train['sentiment'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.pad_sequences(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5298439-54ee-4bfc-9820-2869269fa245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52666bfb-f482-4122-a3d2-97da41f41434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   68  146   41]\n",
      " [   0    0    0 ...    0  397   65]\n",
      " [   0    0    0 ...    0    0   11]\n",
      " ...\n",
      " [   0    0    0 ...  372   10    3]\n",
      " [   0    0    0 ...   24  542    4]\n",
      " [   0    0    0 ... 2424  199  657]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e77c93f5-425b-4fff-a172-4e2daaca357d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51d8a33f-f82e-4c57-8fc8-7b7293800bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20610 6871 20610 6871\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2f070c-1a67-4f07-a39e-bab15349c1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 01:49:26.345672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 01:49:26.347568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 01:49:26.348844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 01:49:26.803458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 01:49:26.805075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 01:49:26.806627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 01:49:27.482216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 01:49:27.483863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 01:49:27.485453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 01:50:03.125895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 01:50:03.128447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 01:50:03.130682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75913, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 40s 59ms/step - loss: 0.7872 - accuracy: 0.6761 - val_loss: 0.6112 - val_accuracy: 0.7591\n",
      "Epoch 2/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.7766\n",
      "Epoch 2: val_accuracy improved from 0.75913 to 0.79101, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 57s 89ms/step - loss: 0.5629 - accuracy: 0.7766 - val_loss: 0.5298 - val_accuracy: 0.7910\n",
      "Epoch 3/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.8066\n",
      "Epoch 3: val_accuracy improved from 0.79101 to 0.80862, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 70s 109ms/step - loss: 0.4998 - accuracy: 0.8066 - val_loss: 0.4920 - val_accuracy: 0.8086\n",
      "Epoch 4/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.8189\n",
      "Epoch 4: val_accuracy improved from 0.80862 to 0.81400, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 63s 97ms/step - loss: 0.4709 - accuracy: 0.8189 - val_loss: 0.4816 - val_accuracy: 0.8140\n",
      "Epoch 5/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8283\n",
      "Epoch 5: val_accuracy improved from 0.81400 to 0.82026, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 61s 95ms/step - loss: 0.4506 - accuracy: 0.8283 - val_loss: 0.4681 - val_accuracy: 0.8203\n",
      "Epoch 6/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8352\n",
      "Epoch 6: val_accuracy improved from 0.82026 to 0.82186, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 57s 88ms/step - loss: 0.4354 - accuracy: 0.8352 - val_loss: 0.4596 - val_accuracy: 0.8219\n",
      "Epoch 7/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8415\n",
      "Epoch 7: val_accuracy improved from 0.82186 to 0.82288, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 56s 86ms/step - loss: 0.4262 - accuracy: 0.8415 - val_loss: 0.4548 - val_accuracy: 0.8229\n",
      "Epoch 8/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.8429\n",
      "Epoch 8: val_accuracy improved from 0.82288 to 0.82390, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 71s 109ms/step - loss: 0.4141 - accuracy: 0.8429 - val_loss: 0.4503 - val_accuracy: 0.8239\n",
      "Epoch 9/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8494\n",
      "Epoch 9: val_accuracy improved from 0.82390 to 0.82652, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 49s 76ms/step - loss: 0.4057 - accuracy: 0.8494 - val_loss: 0.4509 - val_accuracy: 0.8265\n",
      "Epoch 10/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.8493\n",
      "Epoch 10: val_accuracy improved from 0.82652 to 0.82928, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 42s 66ms/step - loss: 0.3997 - accuracy: 0.8493 - val_loss: 0.4431 - val_accuracy: 0.8293\n",
      "Epoch 11/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8554\n",
      "Epoch 11: val_accuracy did not improve from 0.82928\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.3909 - accuracy: 0.8554 - val_loss: 0.4451 - val_accuracy: 0.8293\n",
      "Epoch 12/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8567\n",
      "Epoch 12: val_accuracy improved from 0.82928 to 0.83190, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.3860 - accuracy: 0.8567 - val_loss: 0.4404 - val_accuracy: 0.8319\n",
      "Epoch 13/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8588\n",
      "Epoch 13: val_accuracy did not improve from 0.83190\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.3830 - accuracy: 0.8588 - val_loss: 0.4454 - val_accuracy: 0.8300\n",
      "Epoch 14/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8623\n",
      "Epoch 14: val_accuracy improved from 0.83190 to 0.83263, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 41s 64ms/step - loss: 0.3752 - accuracy: 0.8623 - val_loss: 0.4406 - val_accuracy: 0.8326\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8617\n",
      "Epoch 15: val_accuracy improved from 0.83263 to 0.83525, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 49s 75ms/step - loss: 0.3725 - accuracy: 0.8617 - val_loss: 0.4360 - val_accuracy: 0.8352\n",
      "Epoch 16/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8625\n",
      "Epoch 16: val_accuracy did not improve from 0.83525\n",
      "645/645 [==============================] - 66s 102ms/step - loss: 0.3667 - accuracy: 0.8625 - val_loss: 0.4409 - val_accuracy: 0.8307\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.8647\n",
      "Epoch 17: val_accuracy did not improve from 0.83525\n",
      "645/645 [==============================] - 64s 100ms/step - loss: 0.3647 - accuracy: 0.8647 - val_loss: 0.4375 - val_accuracy: 0.8310\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8652\n",
      "Epoch 18: val_accuracy did not improve from 0.83525\n",
      "645/645 [==============================] - 52s 81ms/step - loss: 0.3635 - accuracy: 0.8652 - val_loss: 0.4423 - val_accuracy: 0.8316\n",
      "Epoch 19/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8673\n",
      "Epoch 19: val_accuracy did not improve from 0.83525\n",
      "645/645 [==============================] - 51s 80ms/step - loss: 0.3609 - accuracy: 0.8673 - val_loss: 0.4368 - val_accuracy: 0.8345\n",
      "Epoch 20/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8722\n",
      "Epoch 20: val_accuracy improved from 0.83525 to 0.83787, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 50s 78ms/step - loss: 0.3533 - accuracy: 0.8722 - val_loss: 0.4398 - val_accuracy: 0.8379\n",
      "Epoch 21/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8707\n",
      "Epoch 21: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 49s 76ms/step - loss: 0.3508 - accuracy: 0.8707 - val_loss: 0.4392 - val_accuracy: 0.8357\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8711\n",
      "Epoch 22: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 61s 94ms/step - loss: 0.3506 - accuracy: 0.8711 - val_loss: 0.4363 - val_accuracy: 0.8361\n",
      "Epoch 23/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8738\n",
      "Epoch 23: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 64s 99ms/step - loss: 0.3481 - accuracy: 0.8738 - val_loss: 0.4369 - val_accuracy: 0.8344\n",
      "Epoch 24/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8719\n",
      "Epoch 24: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 52s 80ms/step - loss: 0.3476 - accuracy: 0.8719 - val_loss: 0.4384 - val_accuracy: 0.8363\n",
      "Epoch 25/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.8724\n",
      "Epoch 25: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.3435 - accuracy: 0.8724 - val_loss: 0.4394 - val_accuracy: 0.8351\n",
      "Epoch 26/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8736\n",
      "Epoch 26: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.3424 - accuracy: 0.8736 - val_loss: 0.4386 - val_accuracy: 0.8371\n",
      "Epoch 27/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.8758\n",
      "Epoch 27: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 44s 69ms/step - loss: 0.3397 - accuracy: 0.8758 - val_loss: 0.4386 - val_accuracy: 0.8351\n",
      "Epoch 28/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8748\n",
      "Epoch 28: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3413 - accuracy: 0.8748 - val_loss: 0.4401 - val_accuracy: 0.8302\n",
      "Epoch 29/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.8787\n",
      "Epoch 29: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.3360 - accuracy: 0.8787 - val_loss: 0.4357 - val_accuracy: 0.8370\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.8772\n",
      "Epoch 30: val_accuracy did not improve from 0.83787\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.3347 - accuracy: 0.8772 - val_loss: 0.4421 - val_accuracy: 0.8348\n",
      "Epoch 31/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8788\n",
      "Epoch 31: val_accuracy improved from 0.83787 to 0.83816, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 75s 117ms/step - loss: 0.3336 - accuracy: 0.8788 - val_loss: 0.4396 - val_accuracy: 0.8382\n",
      "Epoch 32/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8783\n",
      "Epoch 32: val_accuracy improved from 0.83816 to 0.83845, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 86s 134ms/step - loss: 0.3319 - accuracy: 0.8783 - val_loss: 0.4377 - val_accuracy: 0.8385\n",
      "Epoch 33/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8790\n",
      "Epoch 33: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 82s 128ms/step - loss: 0.3304 - accuracy: 0.8790 - val_loss: 0.4404 - val_accuracy: 0.8364\n",
      "Epoch 34/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8801\n",
      "Epoch 34: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 74s 115ms/step - loss: 0.3296 - accuracy: 0.8801 - val_loss: 0.4383 - val_accuracy: 0.8383\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8806\n",
      "Epoch 35: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 51s 80ms/step - loss: 0.3278 - accuracy: 0.8806 - val_loss: 0.4358 - val_accuracy: 0.8366\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8800\n",
      "Epoch 36: val_accuracy did not improve from 0.83845\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.3279 - accuracy: 0.8800 - val_loss: 0.4363 - val_accuracy: 0.8373\n",
      "Epoch 37/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.8808\n",
      "Epoch 37: val_accuracy improved from 0.83845 to 0.83947, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 51s 79ms/step - loss: 0.3247 - accuracy: 0.8808 - val_loss: 0.4374 - val_accuracy: 0.8395\n",
      "Epoch 38/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8831\n",
      "Epoch 38: val_accuracy did not improve from 0.83947\n",
      "645/645 [==============================] - 45s 70ms/step - loss: 0.3226 - accuracy: 0.8831 - val_loss: 0.4540 - val_accuracy: 0.8319\n",
      "Epoch 39/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8840\n",
      "Epoch 39: val_accuracy improved from 0.83947 to 0.84063, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 43s 66ms/step - loss: 0.3217 - accuracy: 0.8840 - val_loss: 0.4391 - val_accuracy: 0.8406\n",
      "Epoch 40/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8836\n",
      "Epoch 40: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 51s 79ms/step - loss: 0.3183 - accuracy: 0.8836 - val_loss: 0.4453 - val_accuracy: 0.8380\n",
      "Epoch 41/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.8856\n",
      "Epoch 41: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 50s 78ms/step - loss: 0.3161 - accuracy: 0.8856 - val_loss: 0.4395 - val_accuracy: 0.8398\n",
      "Epoch 42/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8850\n",
      "Epoch 42: val_accuracy did not improve from 0.84063\n",
      "645/645 [==============================] - 62s 96ms/step - loss: 0.3156 - accuracy: 0.8850 - val_loss: 0.4428 - val_accuracy: 0.8401\n",
      "Epoch 43/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8871\n",
      "Epoch 43: val_accuracy improved from 0.84063 to 0.84107, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 73s 113ms/step - loss: 0.3154 - accuracy: 0.8871 - val_loss: 0.4371 - val_accuracy: 0.8411\n",
      "Epoch 44/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8838\n",
      "Epoch 44: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 79s 123ms/step - loss: 0.3170 - accuracy: 0.8838 - val_loss: 0.4493 - val_accuracy: 0.8342\n",
      "Epoch 45/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.8869\n",
      "Epoch 45: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.3125 - accuracy: 0.8869 - val_loss: 0.4415 - val_accuracy: 0.8408\n",
      "Epoch 46/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8873\n",
      "Epoch 46: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 42s 65ms/step - loss: 0.3109 - accuracy: 0.8873 - val_loss: 0.4434 - val_accuracy: 0.8401\n",
      "Epoch 47/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.8843\n",
      "Epoch 47: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 47s 73ms/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.4432 - val_accuracy: 0.8379\n",
      "Epoch 48/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8877\n",
      "Epoch 48: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 61s 94ms/step - loss: 0.3109 - accuracy: 0.8877 - val_loss: 0.4455 - val_accuracy: 0.8382\n",
      "Epoch 49/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.8855\n",
      "Epoch 49: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 55s 86ms/step - loss: 0.3099 - accuracy: 0.8855 - val_loss: 0.4421 - val_accuracy: 0.8402\n",
      "Epoch 50/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.8894\n",
      "Epoch 50: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 61s 94ms/step - loss: 0.3075 - accuracy: 0.8894 - val_loss: 0.4427 - val_accuracy: 0.8386\n",
      "Epoch 51/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8894\n",
      "Epoch 51: val_accuracy did not improve from 0.84107\n",
      "645/645 [==============================] - 58s 89ms/step - loss: 0.3090 - accuracy: 0.8894 - val_loss: 0.4486 - val_accuracy: 0.8390\n",
      "Epoch 52/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.8880\n",
      "Epoch 52: val_accuracy improved from 0.84107 to 0.84136, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 63s 97ms/step - loss: 0.3045 - accuracy: 0.8880 - val_loss: 0.4424 - val_accuracy: 0.8414\n",
      "Epoch 53/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8899\n",
      "Epoch 53: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 66s 102ms/step - loss: 0.3032 - accuracy: 0.8899 - val_loss: 0.4461 - val_accuracy: 0.8383\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8884\n",
      "Epoch 54: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 57s 89ms/step - loss: 0.3035 - accuracy: 0.8884 - val_loss: 0.4497 - val_accuracy: 0.8380\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.8886\n",
      "Epoch 55: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 52s 80ms/step - loss: 0.3028 - accuracy: 0.8886 - val_loss: 0.4603 - val_accuracy: 0.8351\n",
      "Epoch 56/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.8895\n",
      "Epoch 56: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.3026 - accuracy: 0.8895 - val_loss: 0.4467 - val_accuracy: 0.8367\n",
      "Epoch 57/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.8913\n",
      "Epoch 57: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 49s 76ms/step - loss: 0.3028 - accuracy: 0.8913 - val_loss: 0.4511 - val_accuracy: 0.8366\n",
      "Epoch 58/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8925\n",
      "Epoch 58: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 59s 91ms/step - loss: 0.2989 - accuracy: 0.8925 - val_loss: 0.4558 - val_accuracy: 0.8369\n",
      "Epoch 59/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8938\n",
      "Epoch 59: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 78s 122ms/step - loss: 0.2972 - accuracy: 0.8938 - val_loss: 0.4508 - val_accuracy: 0.8405\n",
      "Epoch 60/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.8940\n",
      "Epoch 60: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 49s 76ms/step - loss: 0.2973 - accuracy: 0.8940 - val_loss: 0.4471 - val_accuracy: 0.8396\n",
      "Epoch 61/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8936\n",
      "Epoch 61: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 43s 67ms/step - loss: 0.2978 - accuracy: 0.8936 - val_loss: 0.4592 - val_accuracy: 0.8315\n",
      "Epoch 62/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8929\n",
      "Epoch 62: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 47s 72ms/step - loss: 0.2942 - accuracy: 0.8929 - val_loss: 0.4573 - val_accuracy: 0.8339\n",
      "Epoch 63/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.8912\n",
      "Epoch 63: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 47s 74ms/step - loss: 0.2995 - accuracy: 0.8912 - val_loss: 0.4516 - val_accuracy: 0.8363\n",
      "Epoch 64/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8921\n",
      "Epoch 64: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 44s 68ms/step - loss: 0.2941 - accuracy: 0.8921 - val_loss: 0.4559 - val_accuracy: 0.8348\n",
      "Epoch 65/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.8945\n",
      "Epoch 65: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 43s 66ms/step - loss: 0.2949 - accuracy: 0.8945 - val_loss: 0.4606 - val_accuracy: 0.8373\n",
      "Epoch 66/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8951\n",
      "Epoch 66: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 48s 74ms/step - loss: 0.2975 - accuracy: 0.8951 - val_loss: 0.4508 - val_accuracy: 0.8364\n",
      "Epoch 67/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.8959\n",
      "Epoch 67: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 64s 99ms/step - loss: 0.2918 - accuracy: 0.8959 - val_loss: 0.4549 - val_accuracy: 0.8373\n",
      "Epoch 68/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.8980\n",
      "Epoch 68: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 50s 77ms/step - loss: 0.2906 - accuracy: 0.8980 - val_loss: 0.4503 - val_accuracy: 0.8387\n",
      "Epoch 69/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.8951\n",
      "Epoch 69: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 43s 66ms/step - loss: 0.2885 - accuracy: 0.8951 - val_loss: 0.4511 - val_accuracy: 0.8401\n",
      "Epoch 70/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.8955\n",
      "Epoch 70: val_accuracy did not improve from 0.84136\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.2891 - accuracy: 0.8955 - val_loss: 0.4563 - val_accuracy: 0.8406\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf8c935a-a9f4-4eaa-a74c-2b720d606c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 02:52:45.918226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:45.920387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:45.922060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 02:52:46.123378: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 02:52:46.190669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:46.192398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:46.194073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:52:46.603957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:46.606156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:46.608203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:52:46.843233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 02:52:46.916742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:46.918666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:46.920511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:52:47.630541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 02:52:48.155586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:48.158045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:48.160017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:52:48.396674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 02:52:48.470467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:52:48.472388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:52:48.474260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:52:49.171563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.6411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 02:53:54.267688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:53:54.270932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:53:54.273934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 02:53:54.678069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 02:53:54.807490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 02:53:54.811324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 02:53:54.814631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74734, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 78s 114ms/step - loss: 0.8038 - accuracy: 0.6411 - val_loss: 0.6430 - val_accuracy: 0.7473\n",
      "Epoch 2/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.7631\n",
      "Epoch 2: val_accuracy improved from 0.74734 to 0.77150, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 94s 145ms/step - loss: 0.5872 - accuracy: 0.7631 - val_loss: 0.5481 - val_accuracy: 0.7715\n",
      "Epoch 3/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7988\n",
      "Epoch 3: val_accuracy improved from 0.77150 to 0.80527, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 84s 130ms/step - loss: 0.5096 - accuracy: 0.7988 - val_loss: 0.4981 - val_accuracy: 0.8053\n",
      "Epoch 4/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8184\n",
      "Epoch 4: val_accuracy improved from 0.80527 to 0.81051, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 70s 109ms/step - loss: 0.4745 - accuracy: 0.8184 - val_loss: 0.4892 - val_accuracy: 0.8105\n",
      "Epoch 5/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8270\n",
      "Epoch 5: val_accuracy improved from 0.81051 to 0.81866, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 67s 104ms/step - loss: 0.4514 - accuracy: 0.8270 - val_loss: 0.4694 - val_accuracy: 0.8187\n",
      "Epoch 6/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8366\n",
      "Epoch 6: val_accuracy improved from 0.81866 to 0.82070, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 68s 106ms/step - loss: 0.4339 - accuracy: 0.8366 - val_loss: 0.4637 - val_accuracy: 0.8207\n",
      "Epoch 7/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.8422\n",
      "Epoch 7: val_accuracy improved from 0.82070 to 0.82623, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 75s 116ms/step - loss: 0.4207 - accuracy: 0.8422 - val_loss: 0.4534 - val_accuracy: 0.8262\n",
      "Epoch 8/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.8462\n",
      "Epoch 8: val_accuracy did not improve from 0.82623\n",
      "645/645 [==============================] - 78s 121ms/step - loss: 0.4091 - accuracy: 0.8462 - val_loss: 0.4503 - val_accuracy: 0.8248\n",
      "Epoch 9/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.8507\n",
      "Epoch 9: val_accuracy improved from 0.82623 to 0.82855, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 90s 140ms/step - loss: 0.3986 - accuracy: 0.8507 - val_loss: 0.4507 - val_accuracy: 0.8286\n",
      "Epoch 10/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8543\n",
      "Epoch 10: val_accuracy improved from 0.82855 to 0.83103, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 90s 139ms/step - loss: 0.3908 - accuracy: 0.8543 - val_loss: 0.4441 - val_accuracy: 0.8310\n",
      "Epoch 11/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8579\n",
      "Epoch 11: val_accuracy did not improve from 0.83103\n",
      "645/645 [==============================] - 91s 141ms/step - loss: 0.3818 - accuracy: 0.8579 - val_loss: 0.4421 - val_accuracy: 0.8307\n",
      "Epoch 12/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.8594\n",
      "Epoch 12: val_accuracy did not improve from 0.83103\n",
      "645/645 [==============================] - 89s 138ms/step - loss: 0.3773 - accuracy: 0.8594 - val_loss: 0.4435 - val_accuracy: 0.8288\n",
      "Epoch 13/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.8643\n",
      "Epoch 13: val_accuracy improved from 0.83103 to 0.83685, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 93s 145ms/step - loss: 0.3710 - accuracy: 0.8643 - val_loss: 0.4315 - val_accuracy: 0.8369\n",
      "Epoch 14/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8631\n",
      "Epoch 14: val_accuracy did not improve from 0.83685\n",
      "645/645 [==============================] - 80s 125ms/step - loss: 0.3660 - accuracy: 0.8631 - val_loss: 0.4342 - val_accuracy: 0.8326\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8674\n",
      "Epoch 15: val_accuracy did not improve from 0.83685\n",
      "645/645 [==============================] - 87s 135ms/step - loss: 0.3582 - accuracy: 0.8674 - val_loss: 0.4392 - val_accuracy: 0.8338\n",
      "Epoch 16/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8699\n",
      "Epoch 16: val_accuracy did not improve from 0.83685\n",
      "645/645 [==============================] - 82s 127ms/step - loss: 0.3551 - accuracy: 0.8699 - val_loss: 0.4336 - val_accuracy: 0.8352\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8699\n",
      "Epoch 17: val_accuracy did not improve from 0.83685\n",
      "645/645 [==============================] - 71s 111ms/step - loss: 0.3516 - accuracy: 0.8699 - val_loss: 0.4285 - val_accuracy: 0.8366\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8724\n",
      "Epoch 18: val_accuracy improved from 0.83685 to 0.84005, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 73s 113ms/step - loss: 0.3471 - accuracy: 0.8724 - val_loss: 0.4305 - val_accuracy: 0.8401\n",
      "Epoch 19/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.8736\n",
      "Epoch 19: val_accuracy did not improve from 0.84005\n",
      "645/645 [==============================] - 88s 136ms/step - loss: 0.3445 - accuracy: 0.8736 - val_loss: 0.4305 - val_accuracy: 0.8379\n",
      "Epoch 20/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8742\n",
      "Epoch 20: val_accuracy did not improve from 0.84005\n",
      "645/645 [==============================] - 99s 154ms/step - loss: 0.3418 - accuracy: 0.8742 - val_loss: 0.4317 - val_accuracy: 0.8386\n",
      "Epoch 21/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.8760\n",
      "Epoch 21: val_accuracy improved from 0.84005 to 0.84165, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 77s 119ms/step - loss: 0.3385 - accuracy: 0.8760 - val_loss: 0.4298 - val_accuracy: 0.8417\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8756\n",
      "Epoch 22: val_accuracy did not improve from 0.84165\n",
      "645/645 [==============================] - 85s 132ms/step - loss: 0.3366 - accuracy: 0.8756 - val_loss: 0.4309 - val_accuracy: 0.8386\n",
      "Epoch 23/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8774\n",
      "Epoch 23: val_accuracy did not improve from 0.84165\n",
      "645/645 [==============================] - 89s 138ms/step - loss: 0.3357 - accuracy: 0.8774 - val_loss: 0.4313 - val_accuracy: 0.8376\n",
      "Epoch 24/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.8768\n",
      "Epoch 24: val_accuracy did not improve from 0.84165\n",
      "645/645 [==============================] - 87s 134ms/step - loss: 0.3316 - accuracy: 0.8768 - val_loss: 0.4383 - val_accuracy: 0.8377\n",
      "Epoch 25/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8793\n",
      "Epoch 25: val_accuracy improved from 0.84165 to 0.84209, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 121s 187ms/step - loss: 0.3309 - accuracy: 0.8793 - val_loss: 0.4267 - val_accuracy: 0.8421\n",
      "Epoch 26/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8787\n",
      "Epoch 26: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 84s 130ms/step - loss: 0.3301 - accuracy: 0.8787 - val_loss: 0.4312 - val_accuracy: 0.8419\n",
      "Epoch 27/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8808\n",
      "Epoch 27: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 102s 159ms/step - loss: 0.3225 - accuracy: 0.8808 - val_loss: 0.4352 - val_accuracy: 0.8376\n",
      "Epoch 28/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8824\n",
      "Epoch 28: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 69s 107ms/step - loss: 0.3244 - accuracy: 0.8824 - val_loss: 0.4364 - val_accuracy: 0.8395\n",
      "Epoch 29/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8820\n",
      "Epoch 29: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 81s 125ms/step - loss: 0.3234 - accuracy: 0.8820 - val_loss: 0.4325 - val_accuracy: 0.8403\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8816\n",
      "Epoch 30: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 76s 117ms/step - loss: 0.3221 - accuracy: 0.8816 - val_loss: 0.4314 - val_accuracy: 0.8408\n",
      "Epoch 31/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.8840\n",
      "Epoch 31: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 80s 123ms/step - loss: 0.3192 - accuracy: 0.8840 - val_loss: 0.4314 - val_accuracy: 0.8369\n",
      "Epoch 32/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8851\n",
      "Epoch 32: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 108s 167ms/step - loss: 0.3149 - accuracy: 0.8851 - val_loss: 0.4304 - val_accuracy: 0.8417\n",
      "Epoch 33/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8864\n",
      "Epoch 33: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 101s 157ms/step - loss: 0.3130 - accuracy: 0.8864 - val_loss: 0.4284 - val_accuracy: 0.8399\n",
      "Epoch 34/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.8879\n",
      "Epoch 34: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 97s 150ms/step - loss: 0.3110 - accuracy: 0.8879 - val_loss: 0.4302 - val_accuracy: 0.8415\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8850\n",
      "Epoch 35: val_accuracy did not improve from 0.84209\n",
      "645/645 [==============================] - 103s 160ms/step - loss: 0.3117 - accuracy: 0.8850 - val_loss: 0.4290 - val_accuracy: 0.8419\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8861\n",
      "Epoch 36: val_accuracy improved from 0.84209 to 0.84325, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 97s 151ms/step - loss: 0.3111 - accuracy: 0.8861 - val_loss: 0.4340 - val_accuracy: 0.8433\n",
      "Epoch 37/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.8878\n",
      "Epoch 37: val_accuracy did not improve from 0.84325\n",
      "645/645 [==============================] - 104s 161ms/step - loss: 0.3063 - accuracy: 0.8878 - val_loss: 0.4333 - val_accuracy: 0.8371\n",
      "Epoch 38/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.8868\n",
      "Epoch 38: val_accuracy did not improve from 0.84325\n",
      "645/645 [==============================] - 76s 118ms/step - loss: 0.3081 - accuracy: 0.8868 - val_loss: 0.4330 - val_accuracy: 0.8419\n",
      "Epoch 39/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.8889\n",
      "Epoch 39: val_accuracy did not improve from 0.84325\n",
      "645/645 [==============================] - 65s 100ms/step - loss: 0.3057 - accuracy: 0.8889 - val_loss: 0.4364 - val_accuracy: 0.8425\n",
      "Epoch 40/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.8902\n",
      "Epoch 40: val_accuracy improved from 0.84325 to 0.84486, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 68s 105ms/step - loss: 0.3024 - accuracy: 0.8902 - val_loss: 0.4309 - val_accuracy: 0.8449\n",
      "Epoch 41/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8910\n",
      "Epoch 41: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 69s 107ms/step - loss: 0.3021 - accuracy: 0.8910 - val_loss: 0.4293 - val_accuracy: 0.8417\n",
      "Epoch 42/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8920\n",
      "Epoch 42: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 81s 126ms/step - loss: 0.2984 - accuracy: 0.8920 - val_loss: 0.4263 - val_accuracy: 0.8422\n",
      "Epoch 43/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8908\n",
      "Epoch 43: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 107s 166ms/step - loss: 0.3017 - accuracy: 0.8908 - val_loss: 0.4305 - val_accuracy: 0.8425\n",
      "Epoch 44/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.8931\n",
      "Epoch 44: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 100s 154ms/step - loss: 0.2960 - accuracy: 0.8931 - val_loss: 0.4337 - val_accuracy: 0.8434\n",
      "Epoch 45/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8926\n",
      "Epoch 45: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 101s 156ms/step - loss: 0.2929 - accuracy: 0.8926 - val_loss: 0.4393 - val_accuracy: 0.8414\n",
      "Epoch 46/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8938\n",
      "Epoch 46: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 102s 158ms/step - loss: 0.2942 - accuracy: 0.8938 - val_loss: 0.4294 - val_accuracy: 0.8417\n",
      "Epoch 47/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.8945\n",
      "Epoch 47: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 99s 153ms/step - loss: 0.2930 - accuracy: 0.8945 - val_loss: 0.4352 - val_accuracy: 0.8418\n",
      "Epoch 48/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.8940\n",
      "Epoch 48: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 104s 161ms/step - loss: 0.2931 - accuracy: 0.8940 - val_loss: 0.4372 - val_accuracy: 0.8441\n",
      "Epoch 49/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.8947\n",
      "Epoch 49: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 109s 169ms/step - loss: 0.2893 - accuracy: 0.8947 - val_loss: 0.4395 - val_accuracy: 0.8440\n",
      "Epoch 50/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.8967\n",
      "Epoch 50: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 71s 110ms/step - loss: 0.2873 - accuracy: 0.8967 - val_loss: 0.4316 - val_accuracy: 0.8437\n",
      "Epoch 51/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8968\n",
      "Epoch 51: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 72s 111ms/step - loss: 0.2895 - accuracy: 0.8968 - val_loss: 0.4413 - val_accuracy: 0.8435\n",
      "Epoch 52/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8962\n",
      "Epoch 52: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 73s 113ms/step - loss: 0.2874 - accuracy: 0.8962 - val_loss: 0.4472 - val_accuracy: 0.8405\n",
      "Epoch 53/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.8975\n",
      "Epoch 53: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 67s 104ms/step - loss: 0.2836 - accuracy: 0.8975 - val_loss: 0.4376 - val_accuracy: 0.8373\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8959\n",
      "Epoch 54: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 91s 141ms/step - loss: 0.2855 - accuracy: 0.8959 - val_loss: 0.4413 - val_accuracy: 0.8419\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.9004\n",
      "Epoch 55: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 101s 157ms/step - loss: 0.2810 - accuracy: 0.9004 - val_loss: 0.4414 - val_accuracy: 0.8418\n",
      "Epoch 56/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.8966\n",
      "Epoch 56: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 100s 155ms/step - loss: 0.2845 - accuracy: 0.8966 - val_loss: 0.4413 - val_accuracy: 0.8427\n",
      "Epoch 57/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.8988\n",
      "Epoch 57: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 100s 156ms/step - loss: 0.2792 - accuracy: 0.8988 - val_loss: 0.4454 - val_accuracy: 0.8421\n",
      "Epoch 58/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.8998\n",
      "Epoch 58: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 103s 160ms/step - loss: 0.2767 - accuracy: 0.8998 - val_loss: 0.4495 - val_accuracy: 0.8396\n",
      "Epoch 59/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.8983\n",
      "Epoch 59: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 107s 165ms/step - loss: 0.2797 - accuracy: 0.8983 - val_loss: 0.4472 - val_accuracy: 0.8390\n",
      "Epoch 60/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9007\n",
      "Epoch 60: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 111s 172ms/step - loss: 0.2771 - accuracy: 0.9007 - val_loss: 0.4499 - val_accuracy: 0.8385\n",
      "Epoch 61/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9016\n",
      "Epoch 61: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 109s 169ms/step - loss: 0.2756 - accuracy: 0.9016 - val_loss: 0.4470 - val_accuracy: 0.8380\n",
      "Epoch 62/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.9022\n",
      "Epoch 62: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 109s 169ms/step - loss: 0.2742 - accuracy: 0.9022 - val_loss: 0.4459 - val_accuracy: 0.8412\n",
      "Epoch 63/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9019\n",
      "Epoch 63: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 107s 165ms/step - loss: 0.2754 - accuracy: 0.9019 - val_loss: 0.4493 - val_accuracy: 0.8428\n",
      "Epoch 64/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9021\n",
      "Epoch 64: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 112s 173ms/step - loss: 0.2763 - accuracy: 0.9021 - val_loss: 0.4429 - val_accuracy: 0.8383\n",
      "Epoch 65/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 107s 166ms/step - loss: 0.2713 - accuracy: 0.9032 - val_loss: 0.4545 - val_accuracy: 0.8392\n",
      "Epoch 66/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9023\n",
      "Epoch 66: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 112s 174ms/step - loss: 0.2706 - accuracy: 0.9023 - val_loss: 0.4494 - val_accuracy: 0.8421\n",
      "Epoch 67/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9028\n",
      "Epoch 67: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 114s 177ms/step - loss: 0.2720 - accuracy: 0.9028 - val_loss: 0.4513 - val_accuracy: 0.8385\n",
      "Epoch 68/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.9017\n",
      "Epoch 68: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 113s 175ms/step - loss: 0.2714 - accuracy: 0.9017 - val_loss: 0.4472 - val_accuracy: 0.8431\n",
      "Epoch 69/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.9050\n",
      "Epoch 69: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 115s 178ms/step - loss: 0.2667 - accuracy: 0.9050 - val_loss: 0.4505 - val_accuracy: 0.8414\n",
      "Epoch 70/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.9055\n",
      "Epoch 70: val_accuracy did not improve from 0.84486\n",
      "645/645 [==============================] - 109s 169ms/step - loss: 0.2654 - accuracy: 0.9055 - val_loss: 0.4494 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dde8cb13-3a3d-4dad-b3c5-70be48e717fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 1.0527 - acc: 0.5525WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 20ms/step - loss: 1.0527 - acc: 0.5525 - val_loss: 0.9116 - val_acc: 0.6044\n",
      "Epoch 2/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.8688 - acc: 0.6139WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 12s 18ms/step - loss: 0.8687 - acc: 0.6140 - val_loss: 0.8572 - val_acc: 0.6174\n",
      "Epoch 3/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.8258 - acc: 0.6262WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 20ms/step - loss: 0.8258 - acc: 0.6262 - val_loss: 0.8258 - val_acc: 0.6302\n",
      "Epoch 4/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.7938 - acc: 0.6465WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.7937 - acc: 0.6467 - val_loss: 0.7962 - val_acc: 0.6637\n",
      "Epoch 5/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.7617 - acc: 0.7181WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.7616 - acc: 0.7182 - val_loss: 0.7763 - val_acc: 0.7150\n",
      "Epoch 6/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.7338 - acc: 0.7514WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 21ms/step - loss: 0.7339 - acc: 0.7513 - val_loss: 0.7603 - val_acc: 0.7347\n",
      "Epoch 7/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.7656WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.7108 - acc: 0.7657 - val_loss: 0.7488 - val_acc: 0.7535\n",
      "Epoch 8/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.6789 - acc: 0.7795WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.6789 - acc: 0.7795 - val_loss: 0.7087 - val_acc: 0.7636\n",
      "Epoch 9/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.7986WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.6337 - acc: 0.7984 - val_loss: 0.6831 - val_acc: 0.7596\n",
      "Epoch 10/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.8090WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.5987 - acc: 0.8090 - val_loss: 0.6421 - val_acc: 0.7850\n",
      "Epoch 11/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.8177WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.5768 - acc: 0.8178 - val_loss: 0.6260 - val_acc: 0.7923\n",
      "Epoch 12/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5606 - acc: 0.8220WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.5606 - acc: 0.8220 - val_loss: 0.6151 - val_acc: 0.7952\n",
      "Epoch 13/70\n",
      "641/645 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.8268WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.5427 - acc: 0.8270 - val_loss: 0.6038 - val_acc: 0.7916\n",
      "Epoch 14/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5198 - acc: 0.8329WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 12s 18ms/step - loss: 0.5200 - acc: 0.8328 - val_loss: 0.6006 - val_acc: 0.8018\n",
      "Epoch 15/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5006 - acc: 0.8366WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 12s 19ms/step - loss: 0.5006 - acc: 0.8365 - val_loss: 0.5717 - val_acc: 0.7986\n",
      "Epoch 16/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8429WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.4860 - acc: 0.8429 - val_loss: 0.5762 - val_acc: 0.8076\n",
      "Epoch 17/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.8478WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.4740 - acc: 0.8479 - val_loss: 0.5594 - val_acc: 0.8037\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4649 - acc: 0.8525WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.4649 - acc: 0.8525 - val_loss: 0.5526 - val_acc: 0.8150\n",
      "Epoch 19/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4552 - acc: 0.8576WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.4554 - acc: 0.8575 - val_loss: 0.5552 - val_acc: 0.8153\n",
      "Epoch 20/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8600WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.4494 - acc: 0.8599 - val_loss: 0.5806 - val_acc: 0.7993\n",
      "Epoch 21/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8639WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.4429 - acc: 0.8639 - val_loss: 0.5514 - val_acc: 0.8198\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4366 - acc: 0.8654WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.4366 - acc: 0.8654 - val_loss: 0.5491 - val_acc: 0.8163\n",
      "Epoch 23/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4317 - acc: 0.8676WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.4317 - acc: 0.8676 - val_loss: 0.5525 - val_acc: 0.8120\n",
      "Epoch 24/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8703WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.4265 - acc: 0.8701 - val_loss: 0.5784 - val_acc: 0.7997\n",
      "Epoch 25/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.8710WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 21ms/step - loss: 0.4226 - acc: 0.8710 - val_loss: 0.5473 - val_acc: 0.8184\n",
      "Epoch 26/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4171 - acc: 0.8745WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.4171 - acc: 0.8745 - val_loss: 0.5687 - val_acc: 0.8070\n",
      "Epoch 27/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8737WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.4129 - acc: 0.8736 - val_loss: 0.5798 - val_acc: 0.8056\n",
      "Epoch 28/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8760WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.4087 - acc: 0.8760 - val_loss: 0.5559 - val_acc: 0.8159\n",
      "Epoch 29/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4052 - acc: 0.8786WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.4049 - acc: 0.8787 - val_loss: 0.5549 - val_acc: 0.8114\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4016 - acc: 0.8782WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.4016 - acc: 0.8782 - val_loss: 0.5621 - val_acc: 0.8057\n",
      "Epoch 31/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8838WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3974 - acc: 0.8837 - val_loss: 0.5463 - val_acc: 0.8157\n",
      "Epoch 32/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8830WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3940 - acc: 0.8829 - val_loss: 0.5485 - val_acc: 0.8214\n",
      "Epoch 33/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8854WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.3903 - acc: 0.8854 - val_loss: 0.5501 - val_acc: 0.8198\n",
      "Epoch 34/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8865WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 21ms/step - loss: 0.3862 - acc: 0.8865 - val_loss: 0.5974 - val_acc: 0.7986\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3833 - acc: 0.8875WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3833 - acc: 0.8875 - val_loss: 0.5571 - val_acc: 0.8210\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3803 - acc: 0.8898WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3803 - acc: 0.8898 - val_loss: 0.5721 - val_acc: 0.8184\n",
      "Epoch 37/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3769 - acc: 0.8927WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 22ms/step - loss: 0.3769 - acc: 0.8927 - val_loss: 0.5595 - val_acc: 0.8137\n",
      "Epoch 38/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3733 - acc: 0.8930WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3733 - acc: 0.8930 - val_loss: 0.5667 - val_acc: 0.8172\n",
      "Epoch 39/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.8947WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3708 - acc: 0.8947 - val_loss: 0.5767 - val_acc: 0.8201\n",
      "Epoch 40/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3679 - acc: 0.8960WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3679 - acc: 0.8960 - val_loss: 0.5653 - val_acc: 0.8210\n",
      "Epoch 41/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3644 - acc: 0.8964WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.3645 - acc: 0.8964 - val_loss: 0.5782 - val_acc: 0.8163\n",
      "Epoch 42/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8980WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3622 - acc: 0.8980 - val_loss: 0.5651 - val_acc: 0.8194\n",
      "Epoch 43/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3597 - acc: 0.8997WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3597 - acc: 0.8997 - val_loss: 0.5679 - val_acc: 0.8153\n",
      "Epoch 44/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3560 - acc: 0.9000WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 20ms/step - loss: 0.3559 - acc: 0.9000 - val_loss: 0.5647 - val_acc: 0.8140\n",
      "Epoch 45/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3537 - acc: 0.9017WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 13s 21ms/step - loss: 0.3537 - acc: 0.9017 - val_loss: 0.5874 - val_acc: 0.8208\n",
      "Epoch 46/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.9023WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3511 - acc: 0.9023 - val_loss: 0.5788 - val_acc: 0.8210\n",
      "Epoch 47/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3491 - acc: 0.9032WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3491 - acc: 0.9032 - val_loss: 0.5851 - val_acc: 0.8153\n",
      "Epoch 48/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3464 - acc: 0.9056WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3464 - acc: 0.9056 - val_loss: 0.6092 - val_acc: 0.7965\n",
      "Epoch 49/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3439 - acc: 0.9074WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3438 - acc: 0.9074 - val_loss: 0.5810 - val_acc: 0.8157\n",
      "Epoch 50/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3409 - acc: 0.9069WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.3408 - acc: 0.9069 - val_loss: 0.5894 - val_acc: 0.8156\n",
      "Epoch 51/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3385 - acc: 0.9091WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 17s 26ms/step - loss: 0.3385 - acc: 0.9091 - val_loss: 0.5972 - val_acc: 0.8105\n",
      "Epoch 52/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3371 - acc: 0.9107WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3371 - acc: 0.9107 - val_loss: 0.5907 - val_acc: 0.8137\n",
      "Epoch 53/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3342 - acc: 0.9107WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 17s 26ms/step - loss: 0.3342 - acc: 0.9107 - val_loss: 0.6006 - val_acc: 0.8176\n",
      "Epoch 54/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.9113WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3322 - acc: 0.9114 - val_loss: 0.5937 - val_acc: 0.8173\n",
      "Epoch 55/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.9124WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.3300 - acc: 0.9123 - val_loss: 0.5950 - val_acc: 0.8168\n",
      "Epoch 56/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.9139WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3272 - acc: 0.9139 - val_loss: 0.5989 - val_acc: 0.8168\n",
      "Epoch 57/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3261 - acc: 0.9140WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3261 - acc: 0.9140 - val_loss: 0.6027 - val_acc: 0.8157\n",
      "Epoch 58/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3235 - acc: 0.9154WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.3236 - acc: 0.9154 - val_loss: 0.6705 - val_acc: 0.7933\n",
      "Epoch 59/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.9172WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3195 - acc: 0.9172 - val_loss: 0.6073 - val_acc: 0.8121\n",
      "Epoch 60/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3196 - acc: 0.9176WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3196 - acc: 0.9176 - val_loss: 0.6104 - val_acc: 0.8159\n",
      "Epoch 61/70\n",
      "642/645 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9177WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.3172 - acc: 0.9178 - val_loss: 0.6504 - val_acc: 0.8016\n",
      "Epoch 62/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.3145 - acc: 0.9196WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.3145 - acc: 0.9196 - val_loss: 0.6151 - val_acc: 0.8088\n",
      "Epoch 63/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3119 - acc: 0.9201WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3121 - acc: 0.9201 - val_loss: 0.6711 - val_acc: 0.7826\n",
      "Epoch 64/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.9213WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3100 - acc: 0.9212 - val_loss: 0.6202 - val_acc: 0.8063\n",
      "Epoch 65/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9228WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3088 - acc: 0.9229 - val_loss: 0.6318 - val_acc: 0.8131\n",
      "Epoch 66/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.9237WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.3073 - acc: 0.9237 - val_loss: 0.6265 - val_acc: 0.8134\n",
      "Epoch 67/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9231WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.3056 - acc: 0.9231 - val_loss: 0.6347 - val_acc: 0.8107\n",
      "Epoch 68/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.9235WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 15s 24ms/step - loss: 0.3032 - acc: 0.9234 - val_loss: 0.6449 - val_acc: 0.7999\n",
      "Epoch 69/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3010 - acc: 0.9257WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 24ms/step - loss: 0.3008 - acc: 0.9258 - val_loss: 0.6300 - val_acc: 0.8091\n",
      "Epoch 70/70\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.9262WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "645/645 [==============================] - 16s 25ms/step - loss: 0.2998 - acc: 0.9262 - val_loss: 0.6638 - val_acc: 0.8109\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.MaxPooling1D(5))\n",
    "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(3,activation='softmax'))\n",
    "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3892f0f-eecb-423f-9a35-d136ffcbac72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 05:08:05.093016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:05.094188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:05.095666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 05:08:05.245124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 05:08:05.291186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:05.292301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:05.293392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44793077-22f8-4724-895a-840c814b85d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 05:08:19.774707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:19.775924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:19.777270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 05:08:19.929344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 05:08:19.976612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:19.977909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:19.979228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 3s - loss: 0.4309 - accuracy: 0.8449 - 3s/epoch - 13ms/step\n",
      "Model accuracy:  0.8448551893234253\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e3de8e3-1f7c-46d3-a66a-885eae3d1c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 05:08:36.595185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:36.596878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:36.598195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-15 05:08:36.756026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-04-15 05:08:36.808442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-15 05:08:36.809826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-15 05:08:36.811237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 3s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c207f73f-caa5-4984-9d17-80d0e9a3e189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "914c6d2d-9524-4bb7-b7c4-e3e6282994bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2413,  203,  118],\n",
       "       [ 329, 1602,   35],\n",
       "       [ 254,  147, 1770]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27f8f419-db22-4639-92bf-3db9d7ee7c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment = ['Neutral','Negative','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa865437-b407-49da-a967-e625b5752018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences([\"\"\"\n",
    "Research Statement\n",
    "Zhangchunsheng\n",
    "Research background\n",
    "I was educated at Sichuan University, majoring in Mechanical Design, Manufacture, and Automatization from 2008 to 2012. But after my graduation, I became more and more interested in computer science and artificial intelligence, and I quit my first job as an automotive engineer at FAW(First Automobile Works) and made up my mind to find a job in computer science and artificial intelligence.\n",
    "\n",
    "In 2016, I got my first programming job in Beijing. In 2018, I joined Bytedance Co., Ltd. and have been working for almost five years since then. I'm familiar with C/C++, GO, Python, PHP, Node.js, and many other programming languages. I can get familiar with any programming language or software framework in a week.\n",
    "\n",
    "During Bytedance, I mainly constructed a CI/CD platform called Bits. Now, the Bits platform has fully supported the mobile app CI/CD process in ByteDance. The whole mobile app CI/CD process, from the developer's first line of code to the delivery of the app to AppStore, is completed through this platform. In constructing platform functions, I mainly develop and maintain the platform's core process and mid-term planning. I currently host our group's agile process stand-up meeting, regularly assigning tasks, checking progress, and reporting timely follow-ups and results.\n",
    "\n",
    "I am very interested in scientific research but have little research experience. However, I think I have a characteristic no one can compare to. I have high execution ability and will stick to the goal once I set it. I believe scientific research should also need this ability.\n",
    "Research interests\n",
    "I don't have a profound understanding of cutting-edge computer science and artificial intelligence, but I think natural language processing, computer vision, and multimodal machine learning are challenging and essential.\n",
    "\n",
    "Although our computer vision is relatively mature, it is still far from biological intelligence. Although computer vision can distinguish people, dogs, and cats, this differs from what humans do in the real world. The computer trains the model through a large amount of data and pictures, then learns to distinguish these. But humans are different. After a child sees a cat, he knows it is a cat and will never misjudge it. If the computer has seen a biological dog and a toy dog that looks alike, it is likely to misjudge them since their images are similar. A child will never mistake a biological dog and a toy dog.\n",
    "\n",
    "The same is true for natural language processing. Although the current ChatGPT is very popular, it does not reason and induct like a human. My colleagues and I have run some tests on ChatGPT. We asked it to establish a regular expression from some English sentences. It is straightforward for people to recognize the pattern. The difficulty lies in generating the regular expression for humans. But ChatGPT still couldn't induct the correct rules after several rounds of questioning. ChatGPT is more like an intelligent search engine. It is just like a child who has learned a lot of knowledge. If you ask him what he has learned, he will quickly come up with the answer, but there seem to be some deficiencies in reasoning and inducting.\n",
    "\n",
    "For multimodal machine learning, I think this is closer to reality. Because it is difficult to understand the meaning of words, sounds, or images alone, even for humans. A classic example is \"Story of Stone Grotto Poet Eating Lions.\" All the Chinese characters in this short article are read in Chinese \"shi.\" You don't know what he is talking about if you don't read the text. So I think what can be applied to people's daily lives should probably be multimodal machine learning.\n",
    "Research plan\n",
    "I think when we use a lot of data to train the model, we are already far from the mechanism of our actual brain. A child doesn't need hundreds or thousands of photos to identify a cat. I wonder if we can use a small number of samples for model training. Just imagine, if we want to make an artificial intelligence that can reason independently, it will face the same complex world as humans. We can't fill it with all possible data and pictures from the moment it is created and let it carry out model training. There are always some scenes that it has never met before. The correct approach should be to let it learn these things through a small amount of training. This is what we should do, and it is also how to make AI closer to humans.\n",
    "\n",
    "\"\"\"])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15af58-fa99-4335-a6ec-17c9eaa11627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
