{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a459394",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d13c1a0-4a27-4032-8986-7585bfae3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @save\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "DATA_HUB['aclImdb'] = (DATA_URL + 'aclImdb_v1.tar.gz', '01ada507287d82875905620988597833ad4e0903')\n",
    "DATA_HUB['glove.6B.100d'] = (DATA_URL + 'glove.6B.100d.zip', 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d921d2a-f152-46c5-ad5a-001708d67432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download(name, cache_dir=os.path.join('.', 'data')):\n",
    "    \"\"\"Download a file inserted into DATA_HUB, return the local filename.\n",
    "\n",
    "    Defined in :numref:`sec_kaggle_house`\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} does not exist in {DATA_HUB}.\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # Hit cache\n",
    "    print(f'Downloading {fname} from {url}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "\n",
    "def download_extract(name, folder=None):\n",
    "    \"\"\"Download and extract a zip/tar file.\n",
    "\n",
    "    Defined in :numref:`sec_kaggle_house`\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, 'Only zip/tar files can be extracted.'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "\n",
    "# @save\n",
    "def read_imdb(data_dir, is_train):\n",
    "    \"\"\"Read the IMDb review dataset text sequences and labels.\n",
    "    data_dir is like\n",
    "    .\n",
    "    |____aclImdb\n",
    "    | |____test\n",
    "    | | |____neg\n",
    "    | | | |____1821_4.txt\n",
    "    | | | |...\n",
    "    | | |____pos\n",
    "    | | | |____2828_2.txt\n",
    "    | | | |...\n",
    "    | |____train\n",
    "    | | |____neg\n",
    "    | | | |____1821_4.txt\n",
    "    | | | |...\n",
    "    | | |____pos\n",
    "    | | | |____2828_2.txt\n",
    "    | | | |...\"\"\"\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test', label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                #\n",
    "                # each review is stored in a file\n",
    "                # review is a long string\n",
    "                #\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                #\n",
    "                # label is used to tell the review is positive or negative\n",
    "                #\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    #\n",
    "    # data is like [\"xxx\", \"xxx\", ...]\n",
    "    # labels is like [1, 0, ...]\n",
    "    #\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def tokenize(lines, token='word'):\n",
    "    \"\"\"Split text lines into word or character tokens.\n",
    "\n",
    "    Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('ERROR: unknown token type: ' + token)\n",
    "\n",
    "\n",
    "def count_corpus(tokens):\n",
    "    \"\"\"Count token frequencies.\n",
    "\n",
    "    Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        \"\"\"Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # Sort according to frequencies\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):  # Index for the unknown token\n",
    "        return self._token_freqs\n",
    "\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "\n",
    "    Defined in :numref:`sec_linear_concise`\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "# @save\n",
    "def load_data_imdb(batch_size, num_steps):\n",
    "    \"\"\"Return data iterators and the vocabulary of the IMDb review dataset.\"\"\"\n",
    "    if os.path.isfile(\"./data/aclImdb_v1.tar.gz\"):\n",
    "        fname = \"./data/aclImdb_v1.tar.gz\"\n",
    "        base_dir = os.path.dirname(fname)\n",
    "        data_dir, ext = os.path.splitext(fname)\n",
    "        if ext == '.zip':\n",
    "            fp = zipfile.ZipFile(fname, 'r')\n",
    "        elif ext in ('.tar', '.gz'):\n",
    "            fp = tarfile.open(fname, 'r')\n",
    "        else:\n",
    "            assert False, 'Only zip/tar files can be extracted.'\n",
    "        # todo optimize later\n",
    "        # extractall is too slow,\n",
    "        # so we assume that as long as there is the zip file,\n",
    "        # there are the corresponding unzip files\n",
    "        # fp.extractall(base_dir)\n",
    "        data_dir = os.path.join(base_dir, 'aclImdb')\n",
    "    else:\n",
    "        data_dir = download_extract('aclImdb', 'aclImdb')\n",
    "    #\n",
    "    # train_data and test_data are like ([\"For a movie that gets no respect ...\", ...], [1, 0, ...])\n",
    "    #\n",
    "    # tuple's first element is the review array\n",
    "    # each element of the review array is a review\n",
    "    #\n",
    "    # tuple's second element is the label\n",
    "    # 1 is positive and 0 is negative\n",
    "    #\n",
    "    train_data = read_imdb(data_dir, True)\n",
    "    test_data = read_imdb(data_dir, False)\n",
    "    #\n",
    "    # train_tokens and test_tokens are like [['For', 'a', 'movie', ...], ...]\n",
    "    # each element of the inner array is a single word\n",
    "    # each element of the outer array is a review\n",
    "    #\n",
    "    train_tokens = tokenize(train_data[0], token='word')\n",
    "    test_tokens = tokenize(test_data[0], token='word')\n",
    "    #\n",
    "    # vocab.idx_to_token is an array like [\"<unk>\", \"<pad>\", \"the\", \"a\", ...]\n",
    "    # each element is a word\n",
    "    # vocab.token_to_idx is a map like {\"<unk>\": 0, \"<pad>\": 1, \"the\": 2, ...}\n",
    "    # key is a word and value is its index in vocab.idx_to_token\n",
    "    #\n",
    "    vocab = Vocab(train_tokens, min_freq=5, reserved_tokens=['<pad>'])\n",
    "    #\n",
    "    # train_features and test_features are like\n",
    "    # [\n",
    "    #   [  324,     2,    20,  ...,     1,     1,     1], # length : num_steps E.g. 500\n",
    "    #   ...\n",
    "    # ] # length: len(train_tokens) E.g. 25000 AKA. total number of reviews\n",
    "    #\n",
    "    # each element of the inner array is its index in vocab.token_to_idx\n",
    "    #\n",
    "    # elements in train_features and test_features have the same length: num_steps\n",
    "    # in this case it is 500\n",
    "    #\n",
    "    # if inner array is longer than num_steps, it will get truncated\n",
    "    # or it shorter than num_steps, it will be padded with 0\n",
    "    #\n",
    "    train_features = torch.tensor([truncate_pad(vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([truncate_pad(vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    #\n",
    "    # load_array put train_features and test_features into a pytorch TensorDataset\n",
    "    # and returned a DataLoader as an iterator\n",
    "    #\n",
    "    # the iterator return data with the number of batch_size E.g. 64\n",
    "    #\n",
    "    train_iter = load_array((train_features, torch.tensor(train_data[1])), batch_size)\n",
    "    test_iter = load_array((test_features, torch.tensor(test_data[1])), batch_size, is_train=False)\n",
    "    #\n",
    "    # X is like\n",
    "    # [\n",
    "    #   [2556, 1913, ...], # total length: 500 AKA. num_steps\n",
    "    #   ...\n",
    "    # ] # total length: 64 AKA. batch_size\n",
    "    #\n",
    "    # y is like\n",
    "    # [1, 0, 1, ...] # total length: 64\n",
    "    #\n",
    "    for X, y in train_iter:\n",
    "        print('X:', X.shape, ', y:', y.shape)  # X: torch.Size([64, 500]) , y: torch.Size([64])\n",
    "        break\n",
    "    print('# batches:', len(train_iter))  # batches: 391; len(train_iter) * batch_size => 391 * 64 ~ 25000 => total number of reviews\n",
    "\n",
    "    return train_iter, test_iter, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a67ffbe-2ee7-488a-99f5-e69ec358959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 500]) , y: torch.Size([64])\n",
      "# batches: 391\n"
     ]
    }
   ],
   "source": [
    "num_steps = 500  # sequence length\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = load_data_imdb(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5966da-a453-4591-b3fb-7deff8b850a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        #\n",
    "        # embedding: A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "        #            This module is used to store word embeddings and retrieve them using indices.\n",
    "        #            The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
    "        # num_embeddings (int) AKA. vocab_size: size of the dictionary of embeddings E.g. 49347\n",
    "        # embedding_dim (int)  AKA. embed_size: the size of each embedding vector    E.g. 100\n",
    "        #\n",
    "        # it is 49347 * 100 in this case\n",
    "        #\n",
    "        # there are 49347 embedding vectors and each embedding vector has 100 elements\n",
    "        #\n",
    "        # self.embedding.weight is like\n",
    "        # [\n",
    "        #  [-0.8094,  1.5452, -0.5332,  ..., -0.7949, -0.6408, -0.4228], # total length: 100\n",
    "        #  ...,\n",
    "        # ] # total length: 49347\n",
    "        #\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        #\n",
    "        # input_size  AKA. embed_size: The number of expected features in the input `x`\n",
    "        # hidden_size AKA. num_hiddens: The number of features in the hidden state `h`\n",
    "        # num_layers: Number of recurrent layers.\n",
    "        # bidirectional: if it is a bidirectional rnn or not\n",
    "        #\n",
    "        # self.encoder\n",
    "        #             .weight_ih_l0\n",
    "        #             .weight_ih_l1\n",
    "        #                   weight_ih_l[k]: the learnable input-hidden weights of the kth layer\n",
    "        #                                   `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n",
    "        #                                   Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`.\n",
    "        #             .weight_ih_l0_reverse\n",
    "        #             .weight_ih_l1_reverse\n",
    "        #\n",
    "        #             .weight_hh_l0\n",
    "        #             .weight_hh_l1\n",
    "        #                   weight_hh_l[k] : the learnable hidden-hidden weights of the kth layer\n",
    "        #                                    `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`.\n",
    "        #             .weight_hh_l0_reverse\n",
    "        #             .weight_hh_l1_reverse\n",
    "        #\n",
    "        #\n",
    "        # self.encoder.all_weights is like\n",
    "        # [\n",
    "        #  [\n",
    "        #    (400, 100)\n",
    "        #    (400, 100)\n",
    "        #    (400,)\n",
    "        #    (400,)\n",
    "        #  ],\n",
    "        #  [\n",
    "        #    (400, 100)\n",
    "        #    (400, 100)\n",
    "        #    (400,)\n",
    "        #    (400,)\n",
    "        #  ],\n",
    "        #  [\n",
    "        #    (400, 200)\n",
    "        #    (400, 100)\n",
    "        #    (400,)\n",
    "        #    (400,)\n",
    "        #  ],\n",
    "        #  [\n",
    "        #    (400, 200)\n",
    "        #    (400, 100)\n",
    "        #    (400,)\n",
    "        #    (400,)\n",
    "        #  ]\n",
    "        # ] # total length: 4\n",
    "        #\n",
    "        #\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "        #\n",
    "        # Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "        # in_features: size of each input sample\n",
    "        # out_features: size of each output sample\n",
    "        #\n",
    "        # why 4 and why 2 ???\n",
    "        #\n",
    "        # self.decoder.weight is like\n",
    "        # [\n",
    "        #  [2.4826e-02,  1.9565e-02,  4.2694e-02, ...], # total length: 400\n",
    "        #  ...,\n",
    "        # ] # total length: 2\n",
    "        #\n",
    "        self.decoder = nn.Linear(4 * num_hiddens, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #\n",
    "        # The shape of `inputs` is (batch size, no. of time steps).\n",
    "        # E.g. batch_size * num_steps => 64 * 500\n",
    "        #\n",
    "        # Because LSTM requires its input's first dimension to be the temporal dimension,\n",
    "        # the input is transposed before obtaining token representations.\n",
    "        #\n",
    "        # embeddings is (no. of time steps, batch size, word vector dimension) => (500, 64, 100)\n",
    "        #\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        #\n",
    "        # Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
    "        # Otherwise, it's a no-op.\n",
    "        #\n",
    "        self.encoder.flatten_parameters()\n",
    "        #\n",
    "        # Returns hidden states of the last hidden layer at different time steps.\n",
    "        # outputs is (no. of time steps, batch size, 2 * no. of hidden units) => (500, 64, 2 * 100)\n",
    "        #\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        #\n",
    "        # Concatenate the hidden states at the initial and final time steps\n",
    "        # as the input of the fully connected layer.\n",
    "        # Its shape is (batch size, 4 * no. of hidden units) => (64, 4 * 100)\n",
    "        #\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        #\n",
    "        # outs (64, 2)\n",
    "        #\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881c04e6-3562-4caa-bd13-354d751a711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cb30db-0abd-4a9d-9a0f-b7d5322810d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, devices = 100, 100, 2, try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4e3c10-fb93-4e9b-8214-8488e6a3f5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(49347, 100)\n",
       "  (encoder): LSTM(100, 100, num_layers=2, bidirectional=True)\n",
       "  (decoder): Linear(in_features=400, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(module):\n",
    "    #\n",
    "    # perform xavier_uniform_ on each weight property\n",
    "    #\n",
    "    # module\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "    if type(module) == nn.LSTM:\n",
    "        for param in module._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(module._parameters[param])\n",
    "\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056ed8c6-e539-4980-8e76-29129bd0b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_name):\n",
    "        \"\"\"Defined in :numref:`sec_synonyms`\"\"\"\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "\n",
    "        if os.path.isfile(\"./data/glove.6B.100d.zip\"):\n",
    "            fname = \"./data/glove.6B.100d.zip\"\n",
    "            base_dir = os.path.dirname(fname)\n",
    "            data_dir, ext = os.path.splitext(fname)\n",
    "            if ext == '.zip':\n",
    "                fp = zipfile.ZipFile(fname, 'r')\n",
    "            elif ext in ('.tar', '.gz'):\n",
    "                fp = tarfile.open(fname, 'r')\n",
    "            else:\n",
    "                assert False, 'Only zip/tar files can be extracted.'\n",
    "            # todo optimize later\n",
    "            # extractall is too slow,\n",
    "            # so we assume that as long as there is the zip file,\n",
    "            # there are the corresponding unzip files\n",
    "            # fp.extractall(base_dir)\n",
    "            data_dir = os.path.join(base_dir, embedding_name)\n",
    "        else:\n",
    "            data_dir = download_extract(embedding_name)\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        #\n",
    "        # the content of vec.txt is like,\n",
    "        # happy -0.038194 -0.24487 ... -1.2526 0.071624 # total number 100 AKA. the word happy is represented by 100 float value\n",
    "        # each line is a word and 100 float value\n",
    "        #\n",
    "        # idx_to_token is an array, each element is a token (AKA a word)\n",
    "        #\n",
    "        # idx_to_vec is an array like\n",
    "        # [[-0.038194 -0.24487 ... -1.2526 0.071624], ...]\n",
    "        # each element is the vector of the word\n",
    "        #\n",
    "        # token_to_idx is a map, key is token and value is its index in idx_to_token\n",
    "        #\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx) for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "\n",
    "glove_embedding = TokenEmbedding('glove.6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8d366b-1513-472a-a304-f9e5c840a7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# embeds is (49347, 100)\n",
    "#\n",
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape  # torch.Size([49347, 100])\n",
    "\n",
    "#\n",
    "# copy embeds to net.embedding.weight (49347, 100)\n",
    "#\n",
    "net.embedding.weight.data.copy_(embeds)\n",
    "#\n",
    "# not perform GD on this W\n",
    "#\n",
    "net.embedding.weight.requires_grad = False\n",
    "\n",
    "lr, num_epochs = 0.01, 6\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
    "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b87d37c-29b1-4b3e-a860-439cc1112f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\n",
    "\n",
    "    Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "    cmp = astype(y_hat, y.dtype) == y\n",
    "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
    "\n",
    "\n",
    "def train_batch(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"Train for a minibatch with mutiple GPUs (defined in Chapter 13).\n",
    "\n",
    "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
    "    #\n",
    "    # X is (64, 500)\n",
    "    # y is (64,)\n",
    "    # so we handle 64 review data each batch\n",
    "    #\n",
    "    if isinstance(X, list):\n",
    "        # Required for BERT fine-tuning (to be covered later)\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    #\n",
    "    # pred (64, 2)\n",
    "    #\n",
    "    pred = net(X)\n",
    "    #\n",
    "    # l (64,)\n",
    "    #\n",
    "    l = loss(pred, y)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "\n",
    "def use_svg_display():\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"Set the axes for matplotlib.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    "\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n",
    "\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\n",
    "\n",
    "    Defined in :numref:`sec_lenet`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = Accumulator(2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT Fine-tuning (to be covered later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "def train(net, train_iter, test_iter, loss, trainer, num_epochs, devices=try_all_gpus()):\n",
    "    \"\"\"Train a model with mutiple GPUs (defined in Chapter 13).\n",
    "\n",
    "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1], legend=['train loss', 'train acc', 'test acc'])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples,\n",
    "        # no. of predictions\n",
    "        metric = Accumulator(4)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch(net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[3], None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc {metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on {str(devices)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133de8a9-4282-4c12-a102-263e3206466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800420a-3ceb-4363-bc5c-6675520ec5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "# @save\n",
    "def predict_sentiment(net, vocab, sequence):\n",
    "    \"\"\"Predict the sentiment of a text sequence.\"\"\"\n",
    "    sequence = torch.tensor(vocab[sequence.split()], device=try_gpu())\n",
    "    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n",
    "    return 'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae73533-3425-4562-84cf-5cad5fe085d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300141f7-e68f-43da-888b-1e7ccc49aa18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
